### 1. Cost Function

A neural network is trained using a **cost function**, which measures the difference between the predicted outputs and the actual labels. A common cost function is the Mean Squared Error (MSE) for regression tasks or the Cross-Entropy Loss for classification.

#### Mathematical Formulation

Given a set of training examples \( \{ (x^{(i)}, y^{(i)}) \} \), the cost function is typically
defined as:

\[
J(\theta) = \frac{1}{m} \sum_{i=1}^{m} L(h_{\theta}(x^{(i)}), y^{(i)})
\]

where:

- \( h_{\theta}(x) \) is the neural network's output (hypothesis).
- \( L(\cdot) \) is the loss function.
- \( m \) is the number of training samples.

#### Why Cost Function Matters?

- It quantifies how well the model is performing.
- Optimizing it via **gradient descent** improves predictions.

---

### 2. Logistic Regression and Its Loss Function

Logistic regression is a fundamental algorithm for **binary classification**, where the target variable \( y \) takes values in \( \{0, 1\} \).

#### Sigmoid Activation Function

The hypothesis function in logistic regression is defined as:

\[
h_{\theta}(x) = \sigma(\theta^T x) = \frac{1}{1 + e^{-\theta^T x}}
\]

where:

- \( \sigma(\cdot) \) is the sigmoid function, mapping outputs to a probability range \( (0, 1) \).

#### Binary Cross-Entropy Loss

Instead of using Mean Squared Error (which leads to poor convergence properties), logistic regression uses the **binary cross-entropy loss**:

\[
J(\theta) = -\frac{1}{m} \sum_{i=1}^{m} \left[ y^{(i)} \log h_{\theta}(x^{(i)}) + (1 - y^{(i)}) \log(1 - h_{\theta}(x^{(i)})) \right]
\]

where:

- The loss function encourages correct probability estimates by penalizing incorrect predictions heavily.
- When \( y = 1 \), the second term disappears, focusing on maximizing \( h_{\theta}(x) \).
- When \( y = 0 \), the first term disappears, encouraging \( 1 - h_{\theta}(x) \) to be large.

---

### 3. Stochastic Gradient Descent (SGD)

**Gradient Descent** is a fundamental optimization algorithm used to minimize the cost function by adjusting model parameters iteratively.

#### SGD Algorithm Steps

1. Initialize model parameters \( \theta \) randomly.
2. For each **epoch** (complete pass over data):
   - For each training example \( (x^{(i)}, y^{(i)}) \):
     1. Compute gradient \( \nabla J(\theta) \).
     2. Update parameters using the update rule:

\[
\theta = \theta - \alpha \nabla J(\theta)
\]

   - Where \( \alpha \) is the learning rate.
3. Repeat until convergence.

#### Why Use SGD?

- Faster than **batch gradient descent** when dealing with large datasets.
- Introduces noise, which sometimes helps escape local minima.

---

## Backpropagation

Backpropagation (short for **"backward propagation of errors"**) is the fundamental algorithm that used to efficiently compute the gradient of the loss function with respect to the model parameters, allowing the network to update weights and minimize errors during training.

### 1. What is Backpropagation?

Backpropagation is an optimization technique based on **gradient descent**, where the network learns by adjusting its weights in the direction that reduces the error. It consists of two main phases:

1. **Forward Pass** – Compute the output of the network using the current weights.
2. **Backward Pass** – Calculate the gradient of the loss function with respect to the network's parameters and update the weights.

### 2. Steps in Backpropagation

Let's break down backpropagation into a step-by-step process:

#### Step 1: Forward Pass

1. Input data *\(x\)* is passed through the network.
2. Each neuron computes a weighted sum of inputs and applies an activation function:

   \[
   h = f(Wx + b)
   \]

   where *\(W\)* are weights, *\(b\)* is the bias, and *\(f\)* is the activation function (e.g., ReLU, sigmoid).

3. The network produces an output *\(\hat{y}\)*.
4. The loss function *\(L(y, \hat{y})\)* computes the difference between predicted *\(\hat{y}\)* and actual *\(y\)*.

#### Step 2: Compute Loss Gradient

The loss function determines how far the prediction *\(\hat{y}\)* is from the true output *\(y\)*.

Common loss functions include:

- **Mean Squared Error (MSE)** (for regression):

  \[
  L(y, \hat{y}) = \frac{1}{2} (y - \hat{y})^2
  \]

- **Cross-Entropy Loss** (for classification):

  \[
  L(y, \hat{y}) = - \sum y \log(\hat{y})
  \]

#### Step 3: Backward Pass (Chain Rule)

Using the **chain rule of calculus**, backpropagation calculates how the loss function changes with respect to each weight in the network:

1. Compute the derivative of the loss function with respect to the output layer.
2. Propagate this derivative backward layer by layer, adjusting weights accordingly:

   \[
   \frac{\partial L}{\partial W} = \frac{\partial L}{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial h} \cdot \frac{\partial h}{\partial W}
   \]

3. Apply **gradient descent** to update the weights:

   \[
   W = W - \eta \frac{\partial L}{\partial W}
   \]

   where *η* is the learning rate.

--- 

